size : 6
model_count : 10
exploration_constant : 1.0

initial_epsilon : 0.1
epsilon_decay_rate : 1.0
epsilon_lower_bound : 0.1

number_of_episodes : 20
rollouts_per_move : 1000

actor_learning_rate : 0.01

# How ANN definition works: Each game may have some layers which are automatically input before these neurons
# (ex. our Hex agent has some CONV2D layers and a flatten layer first),
# and each game may have some layers which are put after (ex. softmax)
neurons_per_layer : 512, 256, 128, 64, 16, 8

# ADAGRAD, SGD, RMSPROP, ADAM
optimizer : ADAM

# LINEAR, RELU, SIGMOID, TANH, or LEAKYRELU,learning_rate
activation_func : RELU

# Suggested size: size*size * eith er somewhere around 23 specifically or somewhere around a tenth of the total amount of epsiodes
rbuf_size : 6000
# How many times the actor NN is trained over the current RBUF
epochs_per_rbuf : 5
