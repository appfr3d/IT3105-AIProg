size : 6
model_count : 40
exploration_constant : 1.0

initial_epsilon : 0.1
epsilon_decay_rate : 1.0
epsilon_lower_bound : 0.1

number_of_episodes : 1000
timeout : 2

actor_learning_rate : 0.001

# How ANN definition works: Each game may have some layers which are automatically input before these neurons
# (ex. our Hex agent has some CONV2D layers and a flatten layer first),
# and each game may have some layers which are put after (ex. softmax)
neurons_per_layer : 32, 32, 32, 32, 32, 32

# ADAGRAD, SGD, RMSPROP, ADAM
optimizer : ADAM

# LINEAR, RELU, SIGMOID, TANH, or LEAKYRELU,learning_rate
activation_func : RELU

# Suggested size: size*size * eith er somewhere around 23 specifically or somewhere around a tenth of the total amount of epsiodes
rbuf_size : 10000000000000000000
# How many times the actor NN is trained over the current RBUF
epochs_per_rbuf : 10
